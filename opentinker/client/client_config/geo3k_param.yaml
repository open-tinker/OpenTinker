# Geo3K Vision-Language Training Configuration
# Use with: python opentinker/client/geo3k_rl.py

# Project settings
project_name: opentinker
experiment_name: geo3k_vl_training

# Logging
logger_backends: ["console", "wandb"]

# Tracing (optional)
enable_tracing: true
weave_project: null

# WandB (optional)
wandb_key: 2ed6f8544ac3e30d5c08879166cc10d9c6232448

# Model and processor paths
# For VL models, both tokenizer_path and processor_path should point to the same model
tokenizer_path: Qwen/Qwen2.5-VL-7B-Instruct
processor_path: Qwen/Qwen2.5-VL-7B-Instruct # AutoProcessor for VL models

# Data paths - use Geo3K parquet files
data_path: ./data/geo3k/train.parquet
val_data_path: ./data/geo3k/test.parquet

# Training parameters
batch_size: 16
num_workers: 0
num_epochs: 5 # Total epochs
num_steps: null # Or set num_steps for step-based training
save_freq: -1 # Save checkpoint every N steps
test_freq: 5 # Validate every N steps

# Validation parameters
val_batch_size: 32 # Total validation samples

# Generation parameters
temperature: 1.0
top_p: 1.0
max_new_tokens: 2048 # Max tokens per response
max_prompt_tokens: 1024 # Max prompt length (shorter for VL due to image tokens)

# Algorithm
algorithm: "agent_loop"

# RL Algorithm settings
# GRPO is recommended for VL tasks
adv_estimator: "grpo"
rollout_n: 5 # Number of samples per prompt for GRPO

# Interaction configuration
interaction:
  name: geo3k
  class_path: opentinker.environment.gym_environment_interaction.GymEnvironmentInteraction
  config:
    env_host: 0.0.0.0
    env_port: 8088
    env_endpoint: http://${interaction.config.env_host}:${interaction.config.env_port}
    max_steps: 1 # Single-turn geometry problem solving

# Multi-turn settings (single-turn for Geo3K)
multi_turn:
  max_user_turns: 0
  max_assistant_turns: 1
  max_tokens_per_turn: 2048
  weave_project: null
  experiment_name: "geo3k_vl_interaction"

# Scheduler settings
scheduler_url: "http://0.0.0.0:8780"
scheduler_api_key: null

# GPU settings
num_gpus: 4 # Adjust based on your setup
