{"uuid": "c3d6ec6a-de8c-447e-af96-00422334c253", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9224 24-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1623022620672, "architecture": "x86_64", "platform": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.8", "gpu_count": 1, "gpu_type": "NVIDIA RTX PRO 6000 Blackwell Server Edition", "gpu_memory_per_device": 101974081536, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": true}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.11.0", "context": "ENGINE_CONTEXT", "log_time": 1770489240456540160, "source": "production-docker-image", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "kv_cache_memory_bytes": null, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": true, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "8c4eaaa8-b983-41d2-adbe-f487b3936b1a", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9224 24-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1623022620672, "architecture": "x86_64", "platform": "Linux-6.8.0-85-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.8", "gpu_count": 1, "gpu_type": "NVIDIA RTX PRO 6000 Blackwell Server Edition", "gpu_memory_per_device": 101974081536, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": true}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.11.0", "context": "ENGINE_CONTEXT", "log_time": 1770489933148056064, "source": "production-docker-image", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "kv_cache_memory_bytes": null, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": true, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
